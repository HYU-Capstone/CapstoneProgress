{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "DATASET_PATH = os.getcwd() + '/TrainData'\n",
    "\n",
    "MODE = 'folder'\n",
    "\n",
    "IMG_HEIGHT = 100\n",
    "IMG_WIDTH = 100\n",
    "CHANNELS = 3\n",
    "\n",
    "N_CLASSES = 1\n",
    "\n",
    "save_path = 'model'\n",
    "model_name = 'CNN'\n",
    "\n",
    "map_file_name = 'map_categorical_classes.txt'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "full_save_path = os.path.join(save_path, model_name)\n",
    "\n",
    "def create_map_file(file_name, classes, class_to_label_dict):\n",
    "    with open(file_name,'w') as map_file:\n",
    "        for _class in classes:\n",
    "            label = class_to_label_dict[_class]\n",
    "            map_file.write(str(label)+\" \"+_class+\" \"+os.linesep)\n",
    "\n",
    "\n",
    "def read_image(path):\n",
    "    path = str(path, 'utf-8')\n",
    "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\n",
    "def read_data(path, label):\n",
    "    image = read_image(path)\n",
    "    label = np.array(label, dtype=np.int32)\n",
    "    image = image.astype(np.int32)\n",
    "    return image, label\n",
    "    \n",
    "def data_resize_fuction(image_decoded, label):\n",
    "    image_decoded.set_shape([None, None, CHANNELS])\n",
    "    image_resized = tf.image.resize_images(image_decoded, [IMG_HEIGHT,IMG_WIDTH])\n",
    "    return image_resized, label\n",
    "\n",
    "def data_normalization(image, label):\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    return image, label\n",
    "\n",
    "def input_data(dataset_path, mode, batch_size):\n",
    "    imagepaths, labels, classes = list(), list(), list()\n",
    "    class_to_label_dict = {}\n",
    "    \n",
    "    label= 0\n",
    "    \n",
    "    \n",
    "    if mode == 'folder':\n",
    "        files = os.listdir(DATASET_PATH)\n",
    "        if '.DS_Store' in files:\n",
    "            files.remove('.DS_Store')\n",
    "        for file in files:\n",
    "            _class = file.split('_')[0]\n",
    "            if not _class in classes:\n",
    "                classes.append(_class)\n",
    "                class_to_label_dict[_class] = label\n",
    "                label += 1\n",
    "            if file.endswith('.jpg'):\n",
    "                imagepaths.append(os.path.join(DATASET_PATH, file))\n",
    "                labels.append(class_to_label_dict[_class])\n",
    "        print(class_to_label_dict)\n",
    "        create_map_file(map_file_name, classes, class_to_label_dict)\n",
    "        \n",
    "        global N_CLASSES\n",
    "        N_CLASSES = len(classes)\n",
    "        print(classes)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Unknown mode\")\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((imagepaths, labels))\n",
    "    dataset = dataset.map(lambda images, labels:\n",
    "                         tuple(tf.py_func(read_data, [images, labels], [tf.int32, tf.int32])))\n",
    "    \n",
    "    dataset = dataset.map(data_resize_fuction)\n",
    "    dataset = dataset.map(data_normalization)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(buffer_size=(int(len(imagepaths) * 0.4) + 3 * batch_size))\n",
    "    dataset = dataset.batch(batch_size)\n",
    " \n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    image_stacked, label_stacked = iterator.get_next()\n",
    "    next_element = iterator.get_next()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(iterator.initializer)\n",
    "        image, label = sess.run([image_stacked, label_stacked])\n",
    "\n",
    "    return dataset\n",
    "    \n",
    "\n",
    "learning_rate = 0.001\n",
    "num_steps = 100\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "dropout = 0.75\n",
    "\n",
    "\n",
    "\n",
    "dataset = input_data(DATASET_PATH, MODE, batch_size)\n",
    "\n",
    "def conv_net(x, n_classes, dropout, reuse, is_training):\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        ##change value later\n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "        \n",
    "        #fully connected\n",
    "        affine = tf.contrib.layers.flatten(conv2)\n",
    "        affine = tf.layers.dense(affine,1024)\n",
    "        affine = tf.layers.dropout(affine, rate=dropout, training = is_training)\n",
    "        \n",
    "        out = tf.layers.dense(affine, n_classes)\n",
    "        out = tf.nn.softmax(out) if not is_training else out\n",
    "    return out\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "X, Y = iterator.get_next()\n",
    "\n",
    "print(\"N_CLASSES\")\n",
    "print(N_CLASSES)\n",
    "## false로 했을때 value error\n",
    "print(X)\n",
    "logits_train = conv_net(X, N_CLASSES, dropout, reuse=False, is_training=True)\n",
    "logits_test = conv_net(X, N_CLASSES, dropout, reuse=True, is_training=False)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=logits_train, labels=Y))\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(logits_test, 1), tf.cast(Y, tf.int64))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(iterator.initializer)\n",
    "    \n",
    "    \n",
    "    for step in range(1, num_steps+1):\n",
    "        print(step)\n",
    "        if step % display_step == 0:\n",
    "            _, loss, acc = sess.run([train_op, loss_op, accuracy])\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "        else:\n",
    "            sess.run(train_op)\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "    saver.save(sess, full_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##test##\n",
    "\n",
    "# import cv2\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "CHANNELS = 3\n",
    "IMG_HEIGHT = 100\n",
    "IMG_WIDTH = 100\n",
    "save_path = 'model'\n",
    "model_name = 'CNN'\n",
    "full_save_path = os.path.join(save_path, model_name)\n",
    "\n",
    "meta_graph = full_save_path + '.meta'\n",
    "\n",
    "map_file_name = \"map_categorical_classes.txt\"\n",
    "mode = ['label_to_class', 'class_to_label']\n",
    "\n",
    "\n",
    "image_folder_path = \"/Users/NamHyunsil/Desktop/test/jenny/crop_image\"\n",
    "\n",
    "def create_map_dict(file_name, mode):\n",
    "    map_dict = {}\n",
    "    with open(file_name,'r') as map_file:\n",
    "            lines = map_file.readlines()\n",
    "            for line in lines:\n",
    "                split = line.split(' ')\n",
    "                label = int(split[0])\n",
    "                _class = split[1]\n",
    "                if mode == 'label_to_class':\n",
    "                    map_dict[label] = _class\n",
    "                elif mode == 'class_to_label':\n",
    "                    map_dict[_class] = label\n",
    "                else :\n",
    "                    raise Exception(\"Unknown mode\")\n",
    "    return map_dict\n",
    "\n",
    "label_to_class_dict = create_map_dict(map_file_name, mode[0])\n",
    "\n",
    "\n",
    "def run_test(image_path):\n",
    "    image_np = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    image_np = image_np.astype(np.int32)\n",
    "    image_tf = tf.convert_to_tensor(image_np, tf.int32)\n",
    "    image_tf.set_shape([None, None, CHANNELS])\n",
    "    image = tf.image.resize_images(image_tf, [IMG_HEIGHT,IMG_WIDTH])\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    image = tf.expand_dims(image,0)\n",
    "    X = image\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.import_meta_graph(meta_graph)\n",
    "        saver.restore(sess, full_save_path)\n",
    "        logits_test = conv_net(X, N_CLASSES, dropout, reuse=True, is_training=False)\n",
    "        print(sess.run(logits_test))\n",
    "        result = tf.argmax(logits_test, 1)\n",
    "        result = sess.run(result)[0]\n",
    "        print(label_to_class_dict[result])\n",
    "\n",
    "    \n",
    "images = os.walk(image_folder_path).__next__()[2]\n",
    "images.remove('.DS_Store')\n",
    "\n",
    "for image in images:\n",
    "    image_path = os.path.join(image_folder_path, image)\n",
    "    print(image_path)\n",
    "    run_test(image_path)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
